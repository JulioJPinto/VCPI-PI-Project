{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letters\n",
    "\n",
    "## Description\n",
    "\n",
    "Generate an image with the edges of the letters present in this noisy image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 5\n",
    "- Francisco Macedo Ferreira PG55942\n",
    "- Júlio José Medeiros Pereira Pinto PG57883\n",
    "- Ivan Sérgio Rocha Ribeiro PG55950\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# to install cv2 use: pip install opencv-python\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "fname = 'Letters-noisy.png'\n",
    "operations = {}\n",
    "pipeline_order = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDFT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idft(dft):\n",
    "    dft = np.fft.ifftshift(dft)\n",
    "    img_back = cv2.idft(dft)\n",
    "    return cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])\n",
    "\n",
    "operations['idft'] = compute_idft\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dft(img):\n",
    "    dft = cv2.dft(img, flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "    return np.fft.fftshift(dft)\n",
    "\n",
    "operations['dft'] = compute_dft\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inpaint (Black and White)\n",
    "\n",
    "To remove the black and white pixels we decided to use the function inpaint from OpenCV. It allows us to use different interpolation methods. We decided to use Telea’s Fast Marching Method (`cv2.INPAINT_TELEA`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpainting\n",
    "def inpaint_image(img):\n",
    "    mask = (img == 0) | (img == 255)\n",
    "    mask = mask.astype(np.uint8) * 255\n",
    "    \n",
    "    return cv2.inpaint(img, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "operations['inpaint'] = inpaint_image\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Threshold Filter\n",
    "def apply_threshold_filter(dft):\n",
    "    rows, cols = dft.shape[:2]\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    \n",
    "    mask = np.zeros((rows, cols, 2), np.uint8)\n",
    "    mask[crow - 30:crow + 30, ccol - 30:ccol + 30] = 1\n",
    "    return dft * mask\n",
    "\n",
    "operations['threshold'] = apply_threshold_filter\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Blurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_blur(img):\n",
    "    return cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "operations['gaussian'] = apply_gaussian_blur\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_mag(img):\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    \n",
    "    return np.sqrt(np.power(sobelx,2)+np.power(sobely,2))\n",
    "\n",
    "operations['sobel'] = sobel_mag\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_contrast(img):\n",
    "    # Convert to uint8 for histogram equalization\n",
    "    img_uint8 = img.astype(np.uint8)\n",
    "    # Apply histogram equalization\n",
    "    equalized = cv2.equalizeHist(img_uint8)\n",
    "    return equalized\n",
    "\n",
    "operations['contrast'] = apply_contrast\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-Pass Frequency Filter\n",
    "\n",
    "We tested with both a circular center as well as rectangular, it didn´t impact the image as much as we would like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Low-pass Frequency Filter\n",
    "def apply_low_pass_filter(dft):\n",
    "    rows, cols = dft.shape[:2]\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    \n",
    "    mask = np.zeros((rows, cols, 2), np.uint8)\n",
    "    r = 35\n",
    "    # cv2.circle(mask, (ccol, crow), 30, (1, 1), -1)\n",
    "    cv2.rectangle(mask, (ccol - r, crow - r + 10), (ccol + r, crow + r - 10), (1, 1), -1)\n",
    "    return dft * mask\n",
    "\n",
    "operations['low_pass'] = apply_low_pass_filter\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Pass Frequency Filter\n",
    "\n",
    "It was rather useless but we though we might as well try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply High-pass Frequency Filter\n",
    "def apply_high_pass_filter(dft):\n",
    "    rows, cols = dft.shape[:2]\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    \n",
    "    mask = np.ones((rows, cols, 2), np.uint8)\n",
    "    cv2.circle(mask, (ccol, crow), 30, (0, 0), -1)\n",
    "    return dft * mask\n",
    "\n",
    "operations['high_pass'] = apply_high_pass_filter\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notch Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Notch Filter\n",
    "\n",
    "In terms of removing the \"checkboard\" like effect this was one of the most useful approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Notch Filter\n",
    "def apply_notch_filter(dft):\n",
    "    rows, cols = dft.shape[:2]\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    \n",
    "    notch_centers = [(ccol - 30, crow - 20, 10), (ccol + 30, crow + 20, 10), (ccol - 30, crow + 20, 10), (ccol + 30, crow - 20, 10),\n",
    "                     (ccol + 20, crow, 5), (ccol - 20, crow, 5), (ccol - 5, crow + 10, 5), (ccol + 5, crow - 10, 5)\n",
    "                     ]\n",
    "    \n",
    "    mask = np.ones((rows, cols, 2), np.uint8)\n",
    "    for x, y, r in notch_centers:\n",
    "        cv2.circle(mask, (x, y), r, (0, 0), -1)\n",
    "    return dft * mask\n",
    "\n",
    "operations['notch'] = apply_notch_filter\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donut Notch Filter\n",
    "\n",
    "Just something different we decided to try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Donut Notch Filter\n",
    "def apply_donut_notch_filter(dft):\n",
    "    rows, cols = dft.shape[:2]\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    \n",
    "    notch_centers = [(ccol - 30, crow - 20, 10, 30), (ccol + 30, crow + 20, 10, 30)]\n",
    "    \n",
    "    mask = np.ones((rows, cols, 2), np.uint8)\n",
    "    \n",
    "    for x, y, r_inner, r_outer in notch_centers:\n",
    "        cv2.circle(mask, (x, y), r_outer, (0, 0), -1)\n",
    "        cv2.circle(mask, (x, y), r_inner, (1, 1), -1)\n",
    "    return dft * mask\n",
    "\n",
    "operations['donut'] = apply_donut_notch_filter\n",
    "print(operations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Notch Filter\n",
    "\n",
    "Very much like the Low-Pass filter, but this implementations give us a bit more of a way to test it. We tested it with the regular notch_centers array from the Notch Center Function but it looked awful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply Inversed Notch Filter\n",
    "def apply_inversed_notch_filter(dft):\n",
    "    rows, cols = dft.shape[:2]\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    \n",
    "    notch_centers = [(ccol, crow, 30)]\n",
    "\n",
    "    mask = np.zeros((rows, cols, 2), np.uint8)\n",
    "    for x, y, r in notch_centers:\n",
    "        cv2.circle(mask, (x, y), r, (1, 1), -1)\n",
    "    return dft * mask\n",
    "\n",
    "operations['inversed_notch'] = apply_inversed_notch_filter\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image & Analyzing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_image(img):\n",
    "    hist = cv2.calcHist([img.astype(np.uint8)], [0], None, [256], [0, 256])\n",
    "    return hist\n",
    "\n",
    "def apply_analyze_image(img):\n",
    "    hist = analyze_image(img)\n",
    "    # Just the histogram\n",
    "    plt.plot(hist, color='black')\n",
    "    plt.title('Histogram of Image')\n",
    "    plt.show()\n",
    "\n",
    "    return img\n",
    "\n",
    "operations['analyze'] = apply_analyze_image\n",
    "print(operations)\n",
    "\n",
    "\n",
    "def load_image(filename):\n",
    "    img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    hist = analyze_image(img)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    axes[0].imshow(img, cmap='gray')\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].plot(hist, color='black')\n",
    "    axes[1].set_title('Histogram of Image')\n",
    "    plt.show()\n",
    "\n",
    "    return np.float32(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(data, title):\n",
    "    if data.ndim == 2:  # Spatial domain\n",
    "        plt.figure()\n",
    "        plt.title(title)\n",
    "        plt.imshow(data, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    elif data.ndim == 3 and data.shape[-1] == 2:  # Frequency domain\n",
    "        magnitude_spectrum = 20 * np.log(cv2.magnitude(data[:, :, 0], data[:, :, 1]) + 1)\n",
    "        img = compute_idft(data)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        axes[0].imshow(img, cmap='gray')\n",
    "        axes[0].set_title('Reconstructed Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(magnitude_spectrum, cmap='gray')\n",
    "        axes[1].set_title('Magnitude Spectrum')\n",
    "        axes[1].axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute pipeline\n",
    "data = load_image(fname)\n",
    "\n",
    "pipeline_order = [\"inpaint\", \"dft\", \"notch\", \"low_pass\",\"idft\"]\n",
    "for step in pipeline_order:\n",
    "    data = operations[step](data)\n",
    "    plot_result(data, f\"Step: {step}\")\n",
    "\n",
    "plot_result(data, \"Final Result\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
